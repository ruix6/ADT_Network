{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0THqb8oi7cF"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "from task2_regression.models.happyquokka import happyquokka\n",
    "from task2_regression.models.adt_env import ADT\n",
    "from task2_regression.models.vlaai import vlaai\n",
    "from task2_regression.models.eegnet_env import EEGNet\n",
    "from task2_regression.models.fcnn_env import FCNN\n",
    "from task2_regression.models.linear import simple_linear_model\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(data, window_length, hop):\n",
    "    \"\"\"Window data into overlapping windows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: np.ndarray\n",
    "        Data to window. Shape (n_samples, n_channels)\n",
    "    window_length: int\n",
    "        Length of the window in samples.\n",
    "    hop: int\n",
    "        Hop size in samples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Windowed data. Shape (n_windows, window_length, n_channels)\n",
    "    \"\"\"\n",
    "    new_data = np.empty(\n",
    "        ((data.shape[0] - window_length) // hop, window_length, data.shape[1])\n",
    "    )\n",
    "    for i in range(new_data.shape[0]):\n",
    "        new_data[i, :, :] = data[\n",
    "            i * hop : i * hop + window_length, : \n",
    "        ]\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDtpvlLcpWp7",
    "outputId": "a2e29c1d-c58c-459b-b16f-5afa4ded9a54"
   },
   "outputs": [],
   "source": [
    "adt = ADT(chans=64, outputDims=1, F=8, T=16, D=4, heads=4, ff_dim=128, blocks=4, mask=False, use_bias=False, lrate=0.5)\n",
    "adt.build(input_shape=(None, 320, 64))\n",
    "adt.load_weights('task2_regression/experiments/results_ertnet_env_nomask/model.h5')\n",
    "\n",
    "# happyquokka = happyquokka(num_layers=4, embed_dim=64, num_heads=2, d_hid=256)\n",
    "# happyquokka.build(input_shape=(None, 320, 64))\n",
    "# happyquokka.load_weights('task2_regression/experiments/results_happyquokka_env/model.h5')\n",
    "\n",
    "# vlaai = vlaai(output_dim=1)\n",
    "# vlaai.build(input_shape=(None, 320, 64))\n",
    "# vlaai.load_weights('task2_regression/experiments/results_vlaai_env/model.h5')\n",
    "\n",
    "# eegnet = EEGNet(64, 320, 0.06)\n",
    "# eegnet.build(input_shape=(None, 320, 64))\n",
    "# eegnet.load_weights('task2_regression/experiments/results_eegnet_env/model.h5')\n",
    "\n",
    "# fcnn = FCNN(320)\n",
    "# fcnn.build(input_shape=(None, 320, 64))\n",
    "# fcnn.load_weights('task2_regression/experiments/results_fcnn_env/model.h5')\n",
    "\n",
    "# linear = simple_linear_model(integration_window = int(64*0.5), nb_filters=1)\n",
    "# linear.build(input_shape=(None, 320, 64))\n",
    "# linear.load_weights('task2_regression/experiments/results_linear_env/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLEU9HQspf79",
    "outputId": "b814a5b4-8f20-4ae8-e3a1-8d73b8988759"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "paths = glob.glob(\"/workspace/auditory-eeg-challenge-2024/DTU_evaluations/DTU/*.npz\")\n",
    "print(\"Found {} paths for evaluation\".format(len(paths)))\n",
    "subjects = set([\"_\".join(os.path.basename(x).split(\"_\")[:2]) for x in paths])\n",
    "print(\"Found {} subjects for evaluation\".format(len(subjects)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the number of trials that should be evaluated on for each subject\n",
    "# If None, it will evaluate on all trials\n",
    "# You can set this to a lower number to speed up the next code cell\n",
    "nb_evaluation_trials = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbPLIlKu978e",
    "outputId": "f294047e-46fb-4110-df46-2544bd01aa9c"
   },
   "outputs": [],
   "source": [
    "## Run the model evaluation\n",
    "subject_scores = {}\n",
    "boxplot_data = []\n",
    "\n",
    "# Iterate over the subjects in the DTU dataset\n",
    "for subject in subjects:\n",
    "    print(\"Evaluating subject {}\".format(subject))\n",
    "    for index, p in enumerate(\n",
    "        glob.glob(\"/workspace/vlaai-neuro-decoding/evaluation_datasets/DTU/{}_*.npz\".format(subject))\n",
    "    ):\n",
    "        print(\"Gathering scores for {}...\".format(p))\n",
    "        # Load the data\n",
    "        # Data is stored in .npz format with two keys: 'eeg' and 'envelope'\n",
    "        # containing preprocessed EEG and corresponding speech stimulus\n",
    "        # envelope.\n",
    "        data = np.load(p)\n",
    "        eeg = data[\"eeg\"]\n",
    "        envelope = data[\"envelope\"]\n",
    "\n",
    "        # Standardize EEG and envelope\n",
    "        eeg = (eeg - eeg.mean(axis=0, keepdims=True)) / eeg.std(\n",
    "            axis=0, keepdims=True\n",
    "        )\n",
    "        envelope = (\n",
    "            envelope - envelope.mean(axis=0, keepdims=True)\n",
    "        ) / envelope.std(axis=0, keepdims=True)\n",
    "\n",
    "        # Window the data in windows of 5 seconds with 80% overlap\n",
    "        windowed_eeg = window_data(eeg, 320, 64)\n",
    "        windowed_envelope = window_data(envelope, 320, 64)\n",
    "\n",
    "        # Evaluate the model on the overlapping windows\n",
    "        if subject not in subject_scores:\n",
    "            subject_scores[subject] = []\n",
    "        predictions = adt.predict(windowed_eeg)\n",
    "        for pred, true in zip(predictions, windowed_envelope):\n",
    "            r = pearsonr(pred.reshape(-1), true.reshape(-1))\n",
    "            subject_scores[subject] += [r[0]]\n",
    "        if (\n",
    "            nb_evaluation_trials is not None\n",
    "            and index == nb_evaluation_trials - 1\n",
    "        ):\n",
    "            # Stop at this trial for the current subject\n",
    "            break\n",
    "    # Report the mean score for each subject\n",
    "    mean_scores = np.mean(subject_scores[subject])\n",
    "    boxplot_data += [mean_scores]\n",
    "    print(\"Subject {}: {}\".format(subject, mean_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "8qYERJcE-RuL",
    "outputId": "04a988c2-ca75-452f-f797-1c80f034fbb6"
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "df = pd.DataFrame.from_dict({\"ADT network\": boxplot_data})\n",
    "sns.violinplot(data=df, orient=\"v\")\n",
    "plt.ylabel(\"Pearson correlation\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.title(\"Evaluation of the pre-trained ADT network on the DTU dataset\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(\"Median score = {:.2f}\".format(np.median(boxplot_data)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
